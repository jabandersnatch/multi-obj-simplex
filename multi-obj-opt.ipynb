{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: Multi-objective optimization\n",
    "\n",
    "@Author: Juan Andrés Méndez Galvis, Gérman Adolfo Montoya Orozco, Carlos Andrés Loxano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is multi-objective optimization?\n",
    "\n",
    "Multi-objective optimization is a branch of optimization that deals with problems that have more than one objective function to be optimized simultaneously. In this type of problems, the objective functions are usually conflicting, so that improving one of them implies worsening the other. The goal of multi-objective optimization is to find a set of solutions that are optimal in the sense that no other solution is better in all objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we compare solutions in multi-objective optimization? (Pareto dominance)\n",
    "\n",
    "In multi-objective optimization, we need a way to compare solutions. The most common way to do this is by using the concept of **Pareto dominance**. A solution $x$ is said to dominate another solution $y$ if $x$ is better than $y$ in all objectives and strictly better in at least one objective. In other words, $x$ dominates $y$ if $f(x) \\leq f(y)$ for all objectives and $f(x) < f(y)$ for at least one objective. A solution $x$ is said to be Pareto optimal if there is no other solution that dominates it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we find the Pareto optimal set?\n",
    "\n",
    "The Pareto optimal set is the set of all Pareto optimal solutions. In general, finding the Pareto optimal set is a difficult problem. However, in some cases, we can find the Pareto optimal set by solving a series of single-objective optimization problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we solve multi-objective optimization problems using existing optimization frameworks such as GAMS and Pyomo?\n",
    "\n",
    "Both `pyomo` and `GAMS` don't have built-in support for multi-objective optimization right out of the box. However, we can use them to solve multi-objective optimization problems by transforming the multi-objective optimization problem into a single-objective optimization problem. There are several ways to do this, but one common approach is to use a weighted sum of the objective functions. In this approach, we define a weight for each objective function and then solve a single-objective optimization problem that minimizes the weighted sum of the objective functions. By varying the weights, we can explore the Pareto optimal set.\n",
    "\n",
    "However, this approach has some limitations. For example, it assumes that the objectives are commensurable, which means that they can be combined into a single objective using weights. In practice, this is not always the case, and the objectives may be conflicting or incommensurable. In these cases, we need to use other methods to find the Pareto optimal set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is e-constraint method?\n",
    "\n",
    "The e-constraint method is a method for solving multi-objective optimization problems by transforming them into a series of single-objective optimization problems. In this method, we fix one of the objective functions to a specific value (the e-constraint) and then solve a single-objective optimization problem that minimizes or maximizes the other objectives subject to the constraint that the fixed objective is equal to the e-constraint. By varying the e-constraint, we can explore the Pareto optimal set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ε-constraint Method in Multi-objective Optimization\n",
    "\n",
    "The ε-constraint method is a scalarization technique used in multi-objective optimization to convert a multi-objective problem into a series of single-objective problems. This method facilitates the generation of the Pareto front, which represents the set of all non-dominated solutions, showing trade-offs among competing objectives.\n",
    "\n",
    "#### Detailed Explanation of the ε-constraint Algorithm\n",
    "\n",
    "1. **Define the Multi-objective Optimization Problem**: Let's consider a problem with $m$ objectives $f_i(x)$ and $n$ decision variables $\\mathbf{x} = (x_1, x_2, \\dots, x_n)$, subject to $c$ constraints. The general form of the problem can be stated as:\n",
    "   $$\n",
    "   \\text{Minimize/Maximize } \\mathbf{f}(\\mathbf{x}) = (f_1(\\mathbf{x}), f_2(\\mathbf{x}), \\dots, f_m(\\mathbf{x}))\n",
    "   $$\n",
    "   subject to\n",
    "   $$\n",
    "   g_j(\\mathbf{x}) \\leq 0, \\quad j = 1, \\dots, c\n",
    "   $$\n",
    "   where $g_j(\\mathbf{x})$ are the constraint functions.\n",
    "\n",
    "2. **Define the $\\epsilon$ Values**: The $\\epsilon$ values are predefined bounds set for each of the objective functions except for the one being optimized in the current iteration. These bounds are derived either from the range of values that the objective functions can take or are based on specific decision-maker preferences.\n",
    "\n",
    "3. **For Each Objective Function $f_i$**:\n",
    "    - **Fix the Objective Function $f_i$ to the $\\epsilon$ Value**: Convert the objective $f_i$ into a constraint, $f_i(\\mathbf{x}) \\leq \\epsilon_i$, where $\\epsilon_i$ is a fixed bound for $f_i$ during this iteration.\n",
    "    - **Solve the Single-objective Optimization Problem**: Optimize the remaining objectives subject to the new constraint $f_i(\\mathbf{x}) \\leq \\epsilon_i$, along with the original constraints. This step is repeated for different values of $\\epsilon_i$ to explore various trade-offs.\n",
    "    - **Add the Solution to the Pareto Optimal Set**: Each solution that satisfies the constraints and optimizes the objectives within the bounds of $\\epsilon$ is considered Pareto optimal for this specific setting.\n",
    "\n",
    "4. **Return the Pareto Optimal Set**: Collect all Pareto optimal solutions obtained from varying $\\epsilon$ across feasible ranges for each objective.\n",
    "\n",
    "5. **Graph the Pareto Optimal Set (if possible)**: Visualize the Pareto front to illustrate the trade-offs between objectives. This graphical representation is especially useful for decision-makers to understand the consequences of different choices.\n",
    "\n",
    "#### Determining $\\epsilon$ Values\n",
    "\n",
    "The selection of $\\epsilon$ values is crucial for effectively exploring the Pareto front. These values can be determined based on:\n",
    "- **Historical Data**: Analyzing past solutions to identify reasonable bounds for objectives.\n",
    "- **Stakeholder Input**: Engaging with decision-makers to understand their preferences and acceptable ranges for each objective.\n",
    "- **Exploratory Analysis**: Starting with wide ranges and progressively narrowing them based on the solutions obtained.\n",
    "\n",
    "In practice, the $\\epsilon$-constraint method is particularly effective when decision-makers need to explore a manageable number of potential solutions or when there is a need to understand the extreme values that objectives can reach when others are constrained. It provides a systematic way to navigate through the multi-dimensional trade-offs inherent in multi-objective optimization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Considerations**: `pyomo` keeps in memory the previous constraints, so it is necessary to delete them before adding new constraints. For that you can add the following code snippet:\n",
    "```python\n",
    "    def delete_constraints(Model, comp_name):\n",
    "        list_del = [vr for vr in vars(Mode)\n",
    "                    if comp_name == vr\n",
    "                    or vr.startswith(comp_name + '_index')\n",
    "                    or vr.startswith(comp_name + '_domain')\n",
    "        list_del_str = ', '.join(list_del)\n",
    "        for kk in list_del:\n",
    "            Model.del_component(kk)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
